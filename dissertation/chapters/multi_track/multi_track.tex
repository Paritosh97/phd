\documentclass[../../main.tex]{subfiles}
\begin{document}

\chapter{Multi-Track and Non-Linear Synthesis}
\label{ch:multi_track}

\section{Introduction}

\subsection{Background on Sign Language Synthesis}
Sign language synthesis converts written descriptions into animated sign language using avatars. Traditional methods often relied on gloss sequences, but these have limitations in synchronization and context variability. The AZee model provides a hierarchical structure for sign language descriptions, allowing for more detailed and expressive animations. However, the existing AZee low-level synthesis technique was limited in its ability to handle complex, non-linear expressions, leading to a loss of interpolation information.

\subsection{Importance of Multi-Track and Non-Linear Editing}
Multi-track and non-linear editing methods provide significant improvements over traditional linear editing techniques. They allow simultaneous manipulation of multiple animation tracks, supporting the complex, overlapping motions characteristic of natural sign language. This results in more fluid and realistic animations that better capture the subtleties of human signing.

\subsection{Objectives of the Chapter}
This chapter aims to present a novel approach to sign language synthesis using multi-track and non-linear editing techniques. It showcases improvements in animation quality and flexibility, demonstrating how these techniques preserve the dynamics of individual animation blocks and enhance procedural generation capabilities.

\section{Non-Linear Editing}

\subsection{Definition and Principles of Non-Linear Editing}
Non-linear editing refers to the ability to access and edit any frame of a video clip or animation independently of the sequence. This flexibility allows for more sophisticated and precise adjustments, essential for achieving high-quality animations.

\subsection{Application in Animation}
In animation, non-linear editing enables animators to work on individual segments of an animation independently, which is crucial for managing complex animations with multiple overlapping actions.

\subsection{Benefits in Sign Language Synthesis}
Non-linear editing enhances the realism and fluidity of sign language animations. By allowing for simultaneous and overlapping articulations, it ensures that the nuanced movements of sign language are accurately represented, leading to more natural and comprehensible animations.

\section{AZee Score Tree}

\subsection{Overview of the AZee Model}
The AZee model provides a framework for representing sign language utterances as hierarchical structures of production rules. These rules can be parameterized to capture the specific articulatory features and constraints of each sign.

\subsection{Hierarchical Structure of AZee}
AZee uses a tree-like structure, where each node represents a production rule or constraint, and the branches indicate the relationships between these rules. This hierarchical structure allows for a detailed and flexible representation of sign language.

\subsection{Parameterized Signed Forms and Production Rules}
Each sign language utterance in AZee is described using parameterized forms that specify the articulatory features and constraints for that sign. These forms allow for a precise and customizable representation of sign language.

\subsection{Example AZee Expressions and Their Representations}
Illustrate how complex sign language expressions are encoded using AZee. Provide examples and diagrams to demonstrate the hierarchical and parameterized nature of the model, showcasing its ability to represent detailed and nuanced sign language utterances.

\section{AZee Tree as Multi-Track Animation Representation}

\subsection{Conversion of AZee Scores to Multi-Track Timelines}
Explain the process of converting AZee scores into multi-track animation timelines. Highlight the challenges involved and the solutions developed to address these challenges.

\subsection{Algorithm for Multi-Track Synthesis}
Detail the proposed algorithm for synthesizing AZee descriptions without flattening the score, preserving the dynamics of individual animation blocks.

\subsubsection{Rule 1: Timely Evaluation}
\textbf{Problem:} Overlapping blocks with different start times.\\
\textbf{Solution:} Evaluate blocks chronologically to maintain logical sequence.

\subsubsection{Rule 2: Constraint Precedence}
\textbf{Problem:} Overlapping blocks starting simultaneously.\\
\textbf{Solution:} Give precedence to placement constraints over orientation constraints.

\subsubsection{Rule 3: Second Pass for Transpaths}
\textbf{Problem:} Blocks with transpath constraints.\\
\textbf{Solution:} Evaluate these blocks in a second pass after other constraints are resolved.

\subsubsection{Rule 4: Second Pass for Holds}
\textbf{Problem:} Blocks with hold constraints.\\
\textbf{Solution:} Evaluate these blocks in a second pass to ensure dependent constraints are maintained.

\subsection{Non-Conflicting Cases}
\subsubsection{Independent Evaluations}
Cases where blocks do not overlap or affect different bone chains can be evaluated independently. This includes non-overlapping blocks and constraints such as morph and look, which act independently from other constraints.

\section{Implementation and Experimental Results}

\subsection{Implementation in Blender}
Overview of the Blender add-on for AZee synthesis, including key components such as the AZee editor, 3D viewport, non-linear editor, and properties panel. Discuss how the add-on integrates with Blender's existing tools to facilitate the synthesis process.

\subsection{Experimental Results}

WORKS ON ANY AVATAR

Examples of synthesized AZee descriptions, comparing flattened and non-flattened synthesis. Highlight the preservation of dynamics and any potential issues encountered. Discuss the use of Frobenius distance as a metric for evaluating the accuracy of the synthesized animations.

\section{Conclusion and Future Prospects}

\subsection{Conclusion}
Summarize the benefits of the proposed multi-track synthesis algorithm, emphasizing the preservation of dynamics and improved naturalness in sign language animations. Highlight the contributions of this approach to the field of sign language synthesis.

\subsection{Future Prospects}
Discuss potential extensions to this work, such as integrating top-down techniques, handling morph constraints, and reducing robotic movements through advanced techniques like ambient noise analysis and style transfer. Outline possible future research directions and improvements.

\section{Acknowledgement}
This work has been funded by the Bpifrance investment “Structuring Projects for Competitiveness” (PSPC), as part of the Serveur Gestuel project (IVès et 4Dviews Companies, LISN — University Paris-Saclay, and Gipsa-Lab — Grenoble Alpes University).

\section{Bibliographical References}
\begin{itemize}
    \item Bertoldi, N., et al. (2010). On the creation and the annotation of a large-scale Italian-LIS parallel corpus. LREC2010 4th Workshop on the Representation and Processing of Sign Languages: Corpora and Sign Language Technologies, Valletta, Malta.
    \item Filhol, M., Hadjadj, M., Choisier, A. (2014). Non-manual features: the right to indifference. International Conference on Language Resources and Evaluation.
    \item Filhol, M., Mcdonald, J., Wolfe, R. (2017). Synthesizing sign language by connecting linguistically structured descriptions to a multi-track animation system.
    \item Nunnari, F., Filhol, M., Heloir, A. (2018). Animating azee descriptions using off-the-shelf IK solvers. Workshop on the Representation and Processing of Sign Languages.
    \item Smits, R., et al. (2008). iTaSc: a tool for multi-sensor integration in robot manipulation. IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems.
    \item Wolfe, R., et al. (2021). State of the art and future challenges of the portrayal of facial non-manual signals by signing avatar. International Conference on Human-Computer Interaction.
\end{itemize}

\end{document}
