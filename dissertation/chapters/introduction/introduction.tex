\documentclass[../../main.tex]{subfiles}
\begin{document}
\chapter{Introduction}
\label{ch:introduction}

\gls{sl} is a primary mode of communication for the Deaf and hard-of-hearing communities, playing a crucial role in ensuring accessibility and inclusivity across various aspects of life, such as education, media, and public services. With the advancement of technology, there is an increasing need for high-quality \gls{sl} synthesis systems that can produce naturalistic and expressive animations, bridging the communication gaps between signers and non-signers. % todo WRITE IT MYSELF NOT CHATGPT

% todo remove handshapes
\gls{sl} is a rich and complex mode of communication that relies on visual-gestural modalities, utilizing hand shapes, movements, facial expressions, and body postures to convey meaning. These languages are not universal but vary across regions and cultures, each with its own grammar, syntax, and lexicon. As a result, creating effective \gls{sl} synthesis systems requires a deep understanding of both linguistic intricacies and the technical demands of real-time animation.

Despite its critical role in the lives of Deaf individuals, a significant communication gap remains between signers and non-signers, particularly in areas such as education, healthcare, media, and public services. This gap is further exacerbated by a global shortage of qualified \gls{sl} interpreters, making it difficult to provide adequate support to all who need it.

\section{Motivation}
\label{ch:introduction:motivation}

The motivation for this research stems from the urgent need to address the challenges faced by the Deaf community in accessing essential services and engaging in daily life. Currently, \gls{sl} synthesis systems struggle to replicate the full spectrum of \gls{sl}, including the subtle nuances of hand shapes, movements, and facial expressions—elements integral to the grammar and meaning of \gls{sl} itself.

The global shortage of \gls{sl} interpreters is a well-documented issue. In Europe alone, approximately 750,000 Deaf individuals use \gls{sl} as their primary means of communication, yet there are only about 6,600 working \gls{sl} interpreters. This disparity is even greater in countries with limited resources for Deaf education and interpreter training. In many regions, the ratio of interpreters to Deaf individuals is so low that access to services is severely restricted, underscoring the importance of developing automated \gls{sl} synthesis systems as a scalable solution.

The COVID-19 pandemic has further highlighted the critical need for accessible communication, as public health information, educational content, and essential services moved online. The lack of available \gls{sl} interpreters during this time made it increasingly difficult for many Deaf individuals to access vital information, leading to a renewed focus on developing digital tools that enhance communication accessibility, particularly in virtual environments.

Advances in \gls{nlp}, computer graphics, computer vision and machine learning  over the past decade offer promising avenues for overcoming the limitations of current \gls{sl} synthesis systems. Leveraging these technologies could lead to more advanced models capable of generating highly naturalistic and expressive \gls{sl} animations. Such models not only have the potential to improve communication for Deaf individuals but also contribute to the broader goal of creating a more inclusive society.

In addition to addressing the shortage of interpreters, there is a growing recognition of the need for cultural and linguistic diversity in \gls{sl} synthesis. Sign languages are deeply connected to the culture and identity of Deaf communities. Each \gls{sl} reflects the unique culture of its region, and any attempt to synthesize \gls{sl} must respect and preserve this diversity. This requires systems that are not only technically accurate but also culturally sensitive, capable of adapting to the nuances of different \gls{sl} while maintaining the integrity of communication.

Furthermore, \gls{sl} is highly context-dependent, with variations in signs based on factors such as the signer’s region, community, and personal style. Capturing this complexity in a digital format necessitates sophisticated models that can understand and replicate these nuances. Current systems often lack the flexibility to adapt to these variations, leading to animations that may be technically correct but lack the fluidity and expressiveness of natural sign language.

Another important motivation for this research is its potential impact on education. For Deaf students, access to educational content in \gls{sl} is crucial for academic success. However, the availability of such content is often limited, particularly in regions with few \gls{sl} interpreters. Automated \gls{sl} synthesis systems could bridge this gap, enabling the creation of educational materials that are accessible to Deaf students in their native sign language, thereby improving educational outcomes and leveling the playing field.

Finally, the increasing use of virtual environments and avatars in communication presents both challenges and opportunities for \gls{sl} synthesis. As more interactions move online, there is a growing need for avatars that can communicate in \gls{sl} with the same fluency and expressiveness as human signers. This requires advances in both animation technology and the underlying linguistic models that drive these avatars. By developing more sophisticated synthesis systems, it is possible to create avatars capable of meaningful communication with Deaf users, providing a richer and more inclusive online experience.

% todo remove contributions - put them in conclusion
\section{Objectives and Contributions}
\label{ch:introduction:objectives_contributions}

This research is centered on addressing the limitations of existing \gls{sl} synthesis systems and exploring new methods to enhance the naturalness and expressiveness of synthesized \gls{sl} animations. Specifically, this research aims to:

\begin{itemize}
    \item \textbf{Develop new methods for generating more natural and expressive \gls{sl} animations:} The focus here is on improving the quality of \gls{sl} synthesis based on linguistic input that better captures the intricacies of \gls{sl}, including hand shapes, movements, and facial expressions, which are crucial for conveying both the form and meaning of an \gls{sl} \sl{utterance}.
    \item \textbf{Explore the scalability and adaptability of \gls{sl} synthesis:} Given the diversity of \gls{sl} worldwide, it is essential to develop systems that can adapt to different linguistic and cultural contexts. This research will investigate methods to create scalable models that can be easily adapted to various \gls{sl} and avatar systems, ensuring that the technology can be applied globally.
\end{itemize}

The contributions of this research are expected to be multifaceted, offering both theoretical and practical advancements in the field of \gls{sl} synthesis:

\begin{itemize}
    \item \textbf{Introducing novel algorithms for \gls{sl} synthesis:} This research will contribute new techniques and methodologies for synthesizing \gls{sl}, particularly in the areas of avatar rigging, motion interpolation and facial expression generation. These algorithms are designed to improve the realism and fluidity of \gls{sl} animations, making them more natural and understandable for users.
    \item \textbf{Demonstrating improvements in the scalability of \gls{sl}:} The research will include evaluations of the proposed methods, demonstrating their effectiveness in producing \gls{sl} animations.
    \item \textbf{Providing a framework that can be adapted to various \gls{sl} and contexts:} The ultimate goal of this research is to create a flexible and adaptable framework that can be applied to different \gls{sl} and used in a variety of contexts, from education and media to public services.
\end{itemize}

\section{Significance of the Problem}
\label{ch:introduction:significance}

The significance of this research lies in its potential to close the technical gap between \gls{sl} linguists and character animators, facilitating a more seamless collaboration between these fields. Traditionally, \gls{sl} linguists and animators have worked in parallel but largely disconnected domains. \gls{sl} linguists focus on the linguistic structure and cultural context of \gls{sl}, while character animators concentrate on creating visually convincing movements in digital avatars. However, the complexity and nuance of \gls{sl} require a deeper integration of these two areas to produce animations that are both linguistically accurate and visually expressive.

%todo remove AZee
One of the key innovations explored in this research is the use of the AZee framework, which provides a structured linguistic model for \gls{sl}. AZee offers a formalism for encoding the various components of \gls{sl}, including hand shapes, movements, and facial expressions, within a unified system. By leveraging AZee, this research bridges the gap between the abstract linguistic representations of signs and the concrete visual expressions needed for character animation. This approach allows for the generation of \gls{sl} animations that are accurate in form and meaning.
%todo remove AZee
Moreover, a system like AZee allows for lesser reliance on handcrafted animations and allows for the scalability of \gls{sl} synthesis across different languages and cultural contexts. The integration of AZee into the animation pipeline enhances the adaptability of the system, making it possible to quickly generate animations for various \gls{sl}, each with its own unique grammar and style.

In summary, the research contributes to both the field of \gls{sl} linguistics and the domain of computer animation by providing a framework that unites the strengths of both disciplines. It addresses the need for more effective tools that can translate linguistic insights into high-quality, real-time \gls{sl} animations, thus promoting greater accessibility and inclusivity for the Deaf community.

\section{Structure of the Thesis}
\label{ch:introduction:structure}

The structure of this thesis is designed to guide the reader through the research in a logical and coherent manner. Following this introductory chapter, Chapter~\ref{ch:background_work} provides a comprehensive review of the background work, covering existing methods in \gls{sl} synthesis, relevant techniques, and the challenges identified in the literature. This chapter sets the stage for the technical contributions that follow, offering a detailed overview of the current state of the field and the gaps that this research aims to address.

Chapter~\ref{ch:avatar_creation_pose_synthesis} introduces our pipeline of creating a signing avatar as well as generation of simple animations from a linguistic description. This chapter delves into the technical aspects of creating and managing the skeletal structure of avatars, creating posture constraints from a linguistic description, as well as the synthesis on the avatar using a posture constraint optimization algorithm.

Chapter~\ref{ch:multi_track} focuses on synthesis by discussing the multi-track approach to \gls{sl} synthesis. This approach allows for the simultaneous representation of multiple aspects of a sign, such as hand movements, facial expressions, and body postures. By integrating these elements into a cohesive system, the multi-track approach enables for a more scalable and natural model for \gls{sl} synthesis. 

Chapter~\ref{ch:intermediate_blocks_pose_correction} addresses both the creation of intermediate blocks, template matching as well as the application of deep learning techniques for pose correction. The chapter highlights the importance of intermediate blocks in ensuring fluid transitions between different animation elements, discussing how motion curves and templates contribute to achieving lifelike movements. It also introduces new techniques for generating these blocks to enhance the overall realism of the animation. Additionally, the chapter covers pose correction methods using an \gls{sl} pose prior trained on a \gls{mocap} dataset. This ensures that the synthesized animations don't break the generated postures. By presenting new approaches for pose correction this improves the quality of the poses generated by training on a very small amount of \gls{mocap} data. These combined techniques offer a more polished and natural representation of \gls{sl} in animation.

In Chapter~\ref{ch:facial_expressions}, the focus shifts to the synthesis of facial expressions, which are a critical component of \gls{sl}. Facial expressions convey a wealth of information in \gls{sl}, from grammatical markers to emotional cues. This chapter explores the challenges of synthesizing realistic facial expressions and presents new methods for integrating them into \gls{sl} animations.

Finally, Chapter~\ref{ch:conclusion} concludes the thesis by discussing the implications of the findings, their potential applications in real-world scenarios, and offering a summary of the key results along with suggestions for future research. This chapter also reflects on the broader impact of the research, considering how the advancements in \gls{sl} synthesis can contribute to the ongoing efforts to promote accessibility and inclusivity for Deaf individuals.

\section{Publications}

Work presented in this thesis has been the subject of the following publications:

\begin{enumerate}
    \item Paritosh Sharma, Michael Filhol. "Sign Language Synthesis using Pose Priors." In \textit{Proceedings of the 9th International Conference on Movement and Computing (MOCO '24)}, ACM, 2024, Utrecht, Netherlands.
    
    \item Paritosh Sharma, Camille Challant, Michael Filhol. "Facial Expressions for Sign Language Synthesis using FACSHuman and AZee." In \textit{SIGNLANG}, 2024.
    
    \item Paritosh Sharma, Michael Filhol. "Extending Morphs in AZee Using Pose Space Deformations." In \textit{2023 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW)}, IEEE, 2023, pp. 1-5.
    
    \item Paritosh Sharma, Michael Filhol. "Intermediate Block Generation for Multi-Track Sign Language Synthesis." In \textit{Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation (SCA '23)}, ACM, 2023, Los Angeles, CA, USA.
    
    \item Paritosh Sharma. "A Layered Approach to Constrain Signing Avatars." In \textit{VISIGRAPP\_DC 2023}, Scitevents, Feb 2023, Lisbon, Portugal.
    
    \item Paritosh Sharma, Michael Filhol. "Multi-Track Bottom-Up Synthesis from Non-Flattened AZee Scores." In \textit{7th Workshop on Sign Language Translation and Avatar Technology (SLTAT 7)}, Jun 2022, Marseille, France.
\end{enumerate}

\end{document}
