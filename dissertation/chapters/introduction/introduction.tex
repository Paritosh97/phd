\documentclass[../../main.tex]{subfiles}
\begin{document}
\chapter{Introduction}
\label{ch:introduction}

\gls{sl} is the primary mode of communication for the Deaf and hard-of-hearing communities, playing a crucial role in communication across various aspects of life, such as education, media, and public services. However, there is a notable lack of resources and tools to fully integrate \gls{sl}s into these domains, limiting their broader usage and recognition. To address this, we must invest in technologies and systems that empower the language itself, ensuring that \gls{sl} has the tools, platforms, and visibility it deserves to function on equal terms with spoken and written languages.

\gls{sl} is a rich and complex mode of communication that relies on visual-gestural modalities, utilizing movements, facial expressions, and body postures to convey meaning. These languages are not universal but vary across regions and cultures, each with its own grammar, syntax, and lexicon. As a result, creating effective \gls{sl} synthesis systems requires a deep understanding of both linguistic intricacies and the technical demands of real-time animation.

\section{Motivation}
\label{ch:introduction:motivation}

The motivation for this research stems from the need to work on equipping the language with robust synthesis systems that can replicate the full spectrum of \gls{sl}, including the subtle nuances of gestures and facial expressions—elements integral to the grammar and meaning of \gls{sl} itself.

There is a significant communication gap between signers and non-signers, creating barriers in various aspects of daily life. The global shortage of \gls{sl} interpreters exacerbates this issue. In Europe alone, approximately 750,000 Deaf (or partially deaf) individuals rely on \gls{sl} as their primary means of communication, yet there are only about 6,600 working \gls{sl} interpreters. This disparity is even more pronounced in countries with limited resources for Deaf education and interpreter training. In many regions, the ratio of interpreters to Deaf individuals is so low that access to essential services is severely restricted, highlighting the need for developing automated \gls{sl} synthesis systems as a scalable solution.

The COVID-19 pandemic underscored the critical need for effective communication as public health information, educational content, and essential services moved online. The shortage of available \gls{sl} interpreters during this time made it increasingly difficult for many Deaf individuals to access vital information, leading to a renewed focus on developing digital tools that enhance communication, particularly in virtual environments.

Recent advances in \gls{nlp}, computer graphics, computer vision, and machine learning offer promising avenues to overcome limitations in current \gls{sl} synthesis systems. Leveraging these technologies could lead to more advanced models capable of generating highly naturalistic and expressive \gls{sl} animations. Such models not only have the potential to improve communication for Deaf individuals but also contribute to the broader goal of creating a more inclusive society.

In addition to addressing the shortage of interpreters, there is growing recognition of the need for cultural and linguistic diversity in \gls{sl} synthesis. \gls{sl}s are deeply connected to the culture and identity of Deaf communities. Each \gls{sl} reflects the unique culture of its region, and any attempt to synthesize \gls{sl} must respect and preserve this diversity. This requires systems that are not only technically accurate but also culturally sensitive, capable of adapting to the nuances of different \gls{sl}s while maintaining the integrity of communication.

Furthermore, \gls{sl} is highly context-dependent, with variations in signs based on factors such as the signer’s region, community, and personal style. Capturing this complexity in a digital format necessitates sophisticated models that can understand and replicate these nuances. Current systems often lack the flexibility to adapt to these variations, leading to animations that may be technically correct but lack the fluidity and expressiveness of natural \gls{sl}.

Another important motivation for this research is its potential impact on education. For Deaf students, access to educational content in \gls{sl} is crucial for academic success. However, the availability of such content is often limited, particularly in regions with few \gls{sl} interpreters. Automated \gls{sl} synthesis systems could bridge this gap, enabling the creation of educational materials that are accessible to Deaf students in their native \gls{sl}, thereby improving educational outcomes and leveling the playing field.

Finally, the increasing use of virtual environments and avatars in communication presents both challenges and opportunities for \gls{sl} synthesis. As more interactions move online, there is a growing need for avatars that can communicate in \gls{sl} with the same fluency and expressiveness as human signers. This requires advances in both animation technology and the underlying linguistic models that drive these avatars. By developing more sophisticated synthesis systems, it is possible to create avatars capable of meaningful communication with Deaf users, providing a richer and more inclusive online experience.

\section{Objectives}
\label{ch:introduction:objectives}

This research is centered on addressing the limitations of existing \gls{sl} synthesis systems and exploring new methods to enhance the naturalness and expressiveness of synthesized \gls{sl} animations. Specifically, this research aims to:

\begin{itemize}
    \item \textbf{Develop new methods for generating more natural and expressive \gls{sl} animations:} This research focuses on improving the quality of \gls{sl} synthesis based on linguistic input that better captures the intricacies of \gls{sl}, including gestures and facial expressions, which are crucial for conveying both the form and meaning of a \gls{sl} utterance.
    \item \textbf{Explore the scalability and adaptability of \gls{sl} synthesis:} Given the diversity of \gls{sl}s worldwide, it is essential to develop systems that can adapt to different linguistic and cultural contexts. This research will investigate methods to create scalable models that can be easily adapted to various \gls{sl}s and avatar systems, ensuring that the technology can be applied globally.
\end{itemize}

\section{Significance of the Problem}
\label{ch:introduction:significance}

The significance of this research lies in the fact that the field of \gls{sl} synthesis is still in its early stages, with many challenges yet to be addressed. There is a potential to close the technical gap between \gls{sl} linguists and character animators, facilitating a more seamless collaboration between the two. Traditionally, \gls{sl} linguists and animators have worked in parallel but largely disconnected domains. \gls{sl} linguists focus on the linguistic structure and cultural context of \gls{sl}, while character animators concentrate on creating visually convincing movements in digital avatars. However, the complexity and nuance of \gls{sl} require a deeper integration of these two areas to produce animations that are both linguistically accurate and visually expressive.

This research focuses on using a popular linguistic model as the basis for the \gls{sl} synthesis system. This formalism provides a structured approach to encoding the various components of \gls{sl}, including gestures and facial expressions, within a unified system. This research bridges the gap between the abstract linguistic representations of signs and the concrete visual expressions needed for character animation. A formal system also allows for lesser reliance on handcrafted animations and enables the scalability of \gls{sl} synthesis across different languages and cultural contexts. The integration enhances the adaptability of the system, making it possible to quickly generate animations for various \gls{sl}s, each with its own unique grammar and style.

In summary, the research contributes to both the field of \gls{sl} linguistics and the domain of computer animation by providing a framework that unites the strengths of both disciplines. It addresses the need for more effective tools that can translate linguistic insights into high-quality, real-time \gls{sl} animations, thus promoting greater accessibility and inclusivity for the Deaf community.

\section{Structure of the Thesis}
\label{ch:introduction:structure}

The structure of this thesis is designed to guide the reader through the research in a logical and coherent manner. Following this introductory chapter, Chapter~\ref{ch:background_work} provides a comprehensive review of the background work, covering existing methods in \gls{sl} synthesis, relevant techniques, and the challenges identified in the literature. This chapter sets the stage for the technical contributions that follow, offering a detailed overview of the current state of the field and the gaps that this research aims to address.

Chapter~\ref{ch:avatar_creation_pose_synthesis} introduces our pipeline for creating a signing avatar as well as generating simple animations from a linguistic description. This chapter delves into the technical aspects of creating and managing the skeletal structure of avatars, creating posture constraints from a linguistic description, as well as synthesizing on the avatar using a posture constraint optimization algorithm.

Chapter~\ref{ch:multi_track} focuses on synthesis by discussing the multi-track approach to \gls{sl} synthesis. This approach allows for the simultaneous representation of multiple aspects of a sign, such as hand movements, facial expressions, and body postures. By integrating these elements into a cohesive system, the multi-track approach enables a more scalable and natural model for \gls{sl} synthesis.

Chapter~\ref{ch:intermediate_blocks_pose_correction} addresses both the creation of intermediate blocks, template matching, and the application of deep learning techniques for pose correction. The chapter highlights the importance of intermediate blocks in ensuring fluid transitions between different animation elements, discussing how motion curves and templates contribute to achieving lifelike movements. It also introduces new techniques for generating these blocks to enhance the overall realism of the animation. Additionally, the chapter covers pose correction methods using an \gls{sl} pose prior trained on a \gls{mocap} dataset. This ensures that the synthesized animations don't break the generated postures. By presenting new approaches for pose correction, this research improves the quality of poses generated from a small amount of \gls{mocap} data. These combined techniques offer a more polished and natural representation of \gls{sl} in animation.

In Chapter~\ref{ch:facial_expressions}, the focus shifts to the synthesis of facial expressions, which are a critical component of \gls{sl}. Facial expressions convey a wealth of information in \gls{sl}, from grammatical markers to emotional cues. This chapter explores the challenges of synthesizing realistic facial expressions and presents new methods for integrating them into \gls{sl} animations.

Finally, Chapter~\ref{ch:conclusion} concludes the thesis by discussing the implications of the findings, their potential applications in real-world scenarios, and offering a summary of the key results along with suggestions for future research. This chapter also reflects on the broader impact of the research, considering how the advancements in \gls{sl} synthesis can contribute to the ongoing efforts to promote the language and inclusivity for Deaf individuals.

\end{document}
